{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "# taken from https://github.com/gravins/Anti-SymmetricDGN/blob/main/graph_prop_pred/utils/pna_dataset.py\n",
    "\n",
    "TASKS = ['dist', 'ecc', 'lap', 'conn', 'diam', 'rad']\n",
    "NODE_LVL_TASKS = ['dist', 'ecc', 'lap']\n",
    "GRAPH_LVL_TASKS = ['conn', 'diam', 'rad']\n",
    "\n",
    "class GraphPropDataset(InMemoryDataset):\n",
    "    def __init__(self, root, split, task, dim='25-35', pre_transform=None):\n",
    "        assert split in ['train', 'val', 'test']\n",
    "        assert task in TASKS\n",
    "        if not task in ['dist', 'ecc', 'diam']:\n",
    "            raise NotImplementedError('the only tasks implemented are: dist, ecc, diam')\n",
    "\n",
    "        assert dim in ['15-25', '25-35']\n",
    "        self.dim = dim\n",
    "\n",
    "        self.split = split\n",
    "        self.task = task\n",
    "        super().__init__(root)\n",
    "        self.pre_transform = pre_transform\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "        print(f'Loaded {self.processed_paths[0]}')\n",
    "\n",
    "    @property\n",
    "    def processed_paths(self):\n",
    "        return [os.path.join(self.root, n) for n in self.processed_file_names]\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [os.path.join(f'{self.split}_{self.task}_{self.dim}_data.pt')]\n",
    "\n",
    "    def process(self):\n",
    "        pass  # reuse the data already split by authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('DATA/Diameter/raw'):\n",
    "    os.makedirs('DATA/Diameter/raw')\n",
    "\n",
    "if not os.path.exists('DATA/Eccentricity/raw'):\n",
    "    os.makedirs('DATA/Eccentricity/raw')\n",
    "\n",
    "if not os.path.exists('DATA/SSSP/raw'):\n",
    "    os.makedirs('DATA/SSSP/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch_geometric.data.storage.GlobalStorage was not an allowed global by default. Please use `torch.serialization.add_safe_globals([GlobalStorage])` or the `torch.serialization.safe_globals([GlobalStorage])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 5\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGraphPropDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDATA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     data_list\u001b[38;5;241m.\u001b[39mextend([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m      8\u001b[0m maps \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiam\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiameter/raw\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecc\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEccentricity/raw\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSSP/raw\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m, in \u001b[0;36mGraphPropDataset.__init__\u001b[0;34m(self, root, split, task, dim, pre_transform)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform \u001b[38;5;241m=\u001b[39m pre_transform\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/csnn/lib/python3.10/site-packages/torch/serialization.py:1470\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1462\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1463\u001b[0m                     opened_zipfile,\n\u001b[1;32m   1464\u001b[0m                     map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1467\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1468\u001b[0m                 )\n\u001b[1;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1472\u001b[0m             opened_zipfile,\n\u001b[1;32m   1473\u001b[0m             map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1477\u001b[0m         )\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch_geometric.data.storage.GlobalStorage was not an allowed global by default. Please use `torch.serialization.add_safe_globals([GlobalStorage])` or the `torch.serialization.safe_globals([GlobalStorage])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "for task in ['diam', 'dist', 'ecc']:\n",
    "    data_list = []\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        \n",
    "        dataset = GraphPropDataset('DATA', split, task)\n",
    "        data_list.extend([d for d in dataset])\n",
    "\n",
    "    maps = {'diam': 'Diameter/raw',\n",
    "           'ecc':  'Eccentricity/raw',\n",
    "           'dist': 'SSSP/raw'}\n",
    "\n",
    "    torch.save(data_list, os.path.join('DATA', maps[task], f'{task}_25-35_data_list.pt'))\n",
    "    print(f'Task {task} preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess LRGB Datasets for PyDGN usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import LRGBDataset\n",
    "\n",
    "peptides_func_tr = LRGBDataset('DATA', 'Peptides-func', split='train')\n",
    "peptides_func_vl = LRGBDataset('DATA', 'Peptides-func', split='val')\n",
    "peptides_func_te = LRGBDataset('DATA', 'Peptides-func', split='test')\n",
    "\n",
    "peptides_struct_tr = LRGBDataset('DATA', 'Peptides-struct', split='train')\n",
    "peptides_struct_vl = LRGBDataset('DATA', 'Peptides-struct', split='val')\n",
    "peptides_struct_te = LRGBDataset('DATA', 'Peptides-struct', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_func = [d for d in peptides_func_tr] + [d for d in peptides_func_vl] + [d for d in peptides_func_te]\n",
    "peptides_struct = [d for d in peptides_struct_tr] + [d for d in peptides_struct_vl] + [d for d in peptides_struct_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15535, 15535)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptides_func), len(peptides_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10873, 2331, 2331)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptides_func_tr), len(peptides_func_vl), len(peptides_func_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10873, 2331, 2331)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptides_struct_tr), len(peptides_struct_vl), len(peptides_struct_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import AddLaplacianEigenvectorPE, AddRandomWalkPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RWSE for peptides-func...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferrica/.venv/test-amp/lib/python3.10/site-packages/torch_sparse/matmul.py:97: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  C = torch.sparse.mm(A, B)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "Processing RWSE for peptides-struct...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "rwse = AddRandomWalkPE(walk_length=20)\n",
    "\n",
    "print('Processing RWSE for peptides-func...')\n",
    "i = 0\n",
    "for d in peptides_func:\n",
    "    rwse(d)\n",
    "\n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)\n",
    "        \n",
    "print('Processing RWSE for peptides-struct...')\n",
    "i = 0\n",
    "for d in peptides_struct:\n",
    "    rwse(d)\n",
    "\n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LapPE for peptides-func...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "Processing LapPE for peptides-struct `...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import (\n",
    "    get_laplacian,\n",
    "    to_scipy_sparse_matrix,\n",
    ")\n",
    "\n",
    "def add_node_attr(data, value, attr_name = None):\n",
    "    # TODO Move to `BaseTransform`.\n",
    "    if attr_name is None:\n",
    "        if 'x' in data:\n",
    "            x = data.x.view(-1, 1) if data.x.dim() == 1 else data.x\n",
    "            data.x = torch.cat([x, value.to(x.device, x.dtype)], dim=-1)\n",
    "        else:\n",
    "            data.x = value\n",
    "    else:\n",
    "        data[attr_name] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "# reproducing how LapPE are computed on GPS paper\n",
    "class LapPE_GPS:\n",
    "    # Number of nodes from which to use sparse eigenvector computation:\n",
    "    SPARSE_THRESHOLD: int = 100\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        k: int,\n",
    "        is_undirected: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.k = k  # max_frequencies\n",
    "        self.is_undirected = is_undirected\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def forward(self, data):\n",
    "        eps=1e-12\n",
    "        num_nodes = data.num_nodes\n",
    "\n",
    "        # GET LAPLACIAN\n",
    "        edge_index, edge_weight = get_laplacian(\n",
    "            data.edge_index,\n",
    "            data.edge_weight,\n",
    "            num_nodes=num_nodes,\n",
    "        )\n",
    "        L = to_scipy_sparse_matrix(edge_index, edge_weight, num_nodes)\n",
    "\n",
    "        evals, evects = np.linalg.eigh(L.toarray())\n",
    "\n",
    "        N = len(evals)  # Number of nodes, including disconnected nodes.\n",
    "        assert N == num_nodes\n",
    "        max_freqs = self.k\n",
    "    \n",
    "        # Keep up to the maximum desired number of frequencies.\n",
    "        idx = evals.argsort()[:max_freqs]\n",
    "        evals, evects = evals[idx], np.real(evects[:, idx])\n",
    "        evals = torch.from_numpy(np.real(evals)).clamp_min(0)\n",
    "        evects = torch.from_numpy(evects).float()\n",
    "\n",
    "        # L2 NORMALIZATION\n",
    "        denom = evects.norm(p=2, dim=0, keepdim=True)\n",
    "        denom = denom.clamp_min(eps).expand_as(evects)\n",
    "        evects = evects / denom\n",
    "\n",
    "        # PADDING EIGENVECTORS\n",
    "        if N < max_freqs:\n",
    "            EigVecs = F.pad(evects, (0, max_freqs - N), value=float('nan'))\n",
    "        else:\n",
    "            EigVecs = evects\n",
    "    \n",
    "        # PADDING EIGENVALUES\n",
    "        if N < max_freqs:\n",
    "            EigVals = F.pad(evals, (0, max_freqs - N), value=float('nan')).unsqueeze(0)\n",
    "        else:\n",
    "            EigVals = evals.unsqueeze(0)\n",
    "        EigVals = EigVals.repeat(N, 1).unsqueeze(2)\n",
    "\n",
    "        data = add_node_attr(data, EigVecs, attr_name='laplacian_eigenvector_pe')\n",
    "        data = add_node_attr(data, EigVals, attr_name='laplacian_eigenvalues_pe')\n",
    "        return data\n",
    "\n",
    "# errors = 0\n",
    "print('Processing LapPE for peptides-func...')\n",
    "i = 0\n",
    "for d in peptides_func:\n",
    "    lappe = LapPE_GPS(k=10)\n",
    "    lappe.forward(d)\n",
    "    \n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)\n",
    "\n",
    "print('Processing LapPE for peptides-struct `...')\n",
    "i = 0\n",
    "for d in peptides_struct:\n",
    "    lappe = LapPE_GPS(k=10)\n",
    "    lappe.forward(d)\n",
    "    \n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save processed data\n",
    "torch.save(peptides_func, 'DATA/peptides-func/processed/data.pt')\n",
    "torch.save(peptides_struct, 'DATA/peptides-struct/processed/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
